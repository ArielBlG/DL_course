{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import csv\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'lfw2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pairsDevTrain.txt', 'r') as csvfile:\n",
    "        trainrows = list(csv.reader(csvfile, delimiter='\\t'))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(trainrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainrows = []\n",
    "for index, row in df.iterrows():\n",
    "    if row[3] is None:\n",
    "        trainrows.append([row[0], row[1], row[0], row[2]])\n",
    "    else:\n",
    "        trainrows.append([row[0], row[1], row[2], row[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name1</th>\n",
       "      <th>num1</th>\n",
       "      <th>name2</th>\n",
       "      <th>num2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>1</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>3</td>\n",
       "      <td>Aaron_Peirsol</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron_Sorkin</td>\n",
       "      <td>1</td>\n",
       "      <td>Aaron_Sorkin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abdel_Nasser_Assidi</td>\n",
       "      <td>1</td>\n",
       "      <td>Abdel_Nasser_Assidi</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abdullah</td>\n",
       "      <td>1</td>\n",
       "      <td>Abdullah</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>Tom_Vilsack</td>\n",
       "      <td>1</td>\n",
       "      <td>Wayne_Ferreira</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>Trisha_Meili</td>\n",
       "      <td>1</td>\n",
       "      <td>Vladimiro_Montesinos</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>Ty_Votaw</td>\n",
       "      <td>1</td>\n",
       "      <td>Wayne_Allard</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>Vytas_Danelius</td>\n",
       "      <td>1</td>\n",
       "      <td>Zaini_Abdullah</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2199</th>\n",
       "      <td>Wendy_Kennedy</td>\n",
       "      <td>1</td>\n",
       "      <td>Zara_Akhmadova</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name1 num1                 name2 num2\n",
       "0           Aaron_Peirsol    1         Aaron_Peirsol    2\n",
       "1           Aaron_Peirsol    3         Aaron_Peirsol    4\n",
       "2            Aaron_Sorkin    1          Aaron_Sorkin    2\n",
       "3     Abdel_Nasser_Assidi    1   Abdel_Nasser_Assidi    2\n",
       "4                Abdullah    1              Abdullah    3\n",
       "...                   ...  ...                   ...  ...\n",
       "2195          Tom_Vilsack    1        Wayne_Ferreira    5\n",
       "2196         Trisha_Meili    1  Vladimiro_Montesinos    3\n",
       "2197             Ty_Votaw    1          Wayne_Allard    1\n",
       "2198       Vytas_Danelius    1        Zaini_Abdullah    1\n",
       "2199        Wendy_Kennedy    1        Zara_Akhmadova    1\n",
       "\n",
       "[2200 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(trainrows, columns=['name1', 'num1', 'name2', 'num2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(name, num, shape):\n",
    "    try:\n",
    "        num = int(num)\n",
    "        file_lists = glob(f'{DATA_DIR}/{name}/*')\n",
    "        assert len(file_lists) != 0, \"Shouldn't be empty list!\"\n",
    "        file_lists.sort(key=lambda row: int(row.split('_')[-1][:-4]))\n",
    "        img = cv2.imread(file_lists[num - 1], cv2.IMREAD_COLOR) / 255\n",
    "        if shape is None:\n",
    "            return img\n",
    "        return cv2.resize(img, shape)\n",
    "    except:\n",
    "        print(\"Error in image loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pairs(name_1, num_1, name_2, num_2, shape=None):\n",
    "    return load_image(name_1, num_1, shape), load_image(name_2, num_2, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 105, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_pairs(*df.values[0], (105, 105))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def get_siamese_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (10, 10), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(128, (7, 7), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(128, (4, 4), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.Conv2D(256, (4, 4), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(4096, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(vect):\n",
    "    x, y = vect\n",
    "    sum_square = K.sum(K.square(x-y), axis = 1, keepdims = True)\n",
    "    result = K.maximum(sum_square, K.epsilon())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vecs):\n",
    "    return K.sqrt(K.sum(vecs, axis=1, keepdims=True))\n",
    "\n",
    "def subs_square(vecs):\n",
    "    x, y = vecs\n",
    "    return K.square(x - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_43\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_59 (InputLayer)           [(None, 105, 105, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           [(None, 105, 105, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_28 (Sequential)      (None, 4096)         38960448    input_59[0][0]                   \n",
      "                                                                 input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1)            0           sequential_28[0][0]              \n",
      "                                                                 sequential_28[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 1)            2           lambda_25[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 38,960,450\n",
      "Trainable params: 38,960,450\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "img_shape = (105, 105, 3)\n",
    "\n",
    "input_img1 = layers.Input(img_shape)\n",
    "input_img2 = layers.Input(img_shape)\n",
    "\n",
    "    \n",
    "model = get_siamese_model(img_shape)\n",
    "siamese_model_img1 = model(input_img1)\n",
    "siamese_model_img2 = model(input_img2)\n",
    "\n",
    "\n",
    "# x = layers.Dense(1, activation='sigmoid')([siamese_model_img1, siamese_model_img2])\n",
    "x = layers.Lambda(euclidean_dist)([siamese_model_img1, siamese_model_img2])\n",
    "# x = layers.Lambda(euclidean_distance)(x)\n",
    "x = layers.Dense(1,activation='sigmoid')(x)\n",
    "siamese_net = models.Model(inputs=[input_img1,input_img2],outputs=x)\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "def train_generator():\n",
    "    while True:\n",
    "        for start in range(0, len(df), batch_size):\n",
    "            x_batch_left = []\n",
    "            x_batch_right = []\n",
    "            y_batch = []\n",
    "            end = min(start + batch_size, len(df))\n",
    "            df_train_batch = df[start:end]\n",
    "            for row in df_train_batch.values:\n",
    "                img1, img2 = load_pairs(*row, (105, 105))\n",
    "                label = 1 if row[0] == row[2] else 0\n",
    "                x_batch_left.append(img1)\n",
    "                x_batch_right.append(img2)\n",
    "                y_batch.append(label)\n",
    "            x_batch_left, x_batch_right, y_batch = np.asarray(x_batch_left), np.asarray(x_batch_right), np.asarray(y_batch)\n",
    "            yield [x_batch_left, x_batch_right], y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 6s 169ms/step - loss: 0.9379 - accuracy: 0.5123\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 6s 172ms/step - loss: 0.6933 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 6s 167ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6931 - accuracy: 0.5014\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00030000000260770325.\n",
      "35/35 [==============================] - 6s 168ms/step - loss: 0.6931 - accuracy: 0.5014\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 3.000000142492354e-05.\n",
      "35/35 [==============================] - 6s 167ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5000 ETA: 2s - los\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 3.000000106112566e-06.\n",
      "35/35 [==============================] - 6s 171ms/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "callbacks = [EarlyStopping(monitor='loss', patience=3, verbose=1, min_delta=1e-4),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.1, patience=1, cooldown=0, min_lr=1e-8, verbose=1)]\n",
    "\n",
    "\n",
    "optimizer = SGD(lr = 0.001, momentum = 0.5)\n",
    "siamese_net.compile(optimizer=Adam(lr=0.003), loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "history = siamese_net.fit(x=train_generator(), callbacks=callbacks, epochs=10, verbose = 1, steps_per_epoch=(len(df) // batch_size) + 1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
